{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **1.Dataset Preparation**\n",
        "\n",
        "Datasets: Use publicly available datasets such as FaceForensics++ or Celeb-DF.\n",
        "\n",
        "Preprocessing:\n",
        "- Extract frames from videos (e.g., 10 frames per video).\n",
        "- Resize images to match the Xception modelâ€™s input size (299x299 pixels).\n",
        "- Normalize pixel values to the range [-1, 1] (as required by Xception).\n",
        "- Label frames as real or fake.\n"
      ],
      "metadata": {
        "id": "YpMWumEdDAa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "class DatasetPreparation:\n",
        "    def __init__(self, input_shape=(299, 299, 3), seq_length=10):\n",
        "        self.input_shape = input_shape\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "    def preprocess_image(self, img_path):\n",
        "        \"\"\"Load, resize, and normalize an image.\"\"\"\n",
        "        img = tf.io.read_file(img_path)\n",
        "        img = tf.image.decode_png(img, channels=3)\n",
        "        img = tf.image.resize(img, self.input_shape[:2])\n",
        "        img = tf.keras.applications.xception.preprocess_input(img)  # Normalize to [-1, 1]\n",
        "        return img\n",
        "\n",
        "    def create_dataset(self, directory, batch_size=16):\n",
        "        \"\"\"Create a TensorFlow dataset from images in a directory.\"\"\"\n",
        "        paths = []\n",
        "        labels = []\n",
        "\n",
        "        for class_name in ['real', 'fake']:\n",
        "            class_dir = os.path.join(directory, class_name)\n",
        "            if not os.path.exists(class_dir):\n",
        "                raise ValueError(f\"Directory not found: {class_dir}\")\n",
        "\n",
        "            for img_name in os.listdir(class_dir):\n",
        "                if img_name.lower().endswith('.png'):\n",
        "                    paths.append(os.path.join(class_dir, img_name))\n",
        "                    labels.append(1.0 if class_name == 'real' else 0.0)\n",
        "\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
        "        dataset = dataset.map(\n",
        "            lambda path, label: (self.preprocess_image(path), label),\n",
        "            num_parallel_calls=tf.data.AUTOTUNE\n",
        "        )\n",
        "        dataset = dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "        return dataset\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_bhEm3AqC66T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Model Architecture**\n",
        "\n",
        "MADNet combines:\n",
        "- EfficientNetB0 for spatial feature extraction.\n",
        "- LSTM for temporal sequence analysis.\n",
        "- Dense layers for final classification."
      ],
      "metadata": {
        "id": "6f2e253wDQCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, LSTM, Dropout, TimeDistributed, Concatenate, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "class MADNet:\n",
        "    def __init__(self, input_shape=(299, 299, 3), seq_length=10):\n",
        "        self.input_shape = input_shape\n",
        "        self.seq_length = seq_length\n",
        "        self.model = self._build_model()\n",
        "\n",
        "    def _build_model(self):\n",
        "        \"\"\"Build the MADNet architecture.\"\"\"\n",
        "        # Frame-level input\n",
        "        frame_input = Input(shape=self.input_shape, name=\"Frame_Input\")\n",
        "        base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=self.input_shape)\n",
        "        spatial_features = GlobalAveragePooling2D()(base_model(frame_input))\n",
        "\n",
        "        # Sequence-level input\n",
        "        sequence_input = Input(shape=(self.seq_length, *self.input_shape), name=\"Sequence_Input\")\n",
        "        time_distributed = TimeDistributed(base_model)(sequence_input)\n",
        "        temporal_features = LSTM(256, return_sequences=False)(time_distributed)\n",
        "\n",
        "        # Combine features\n",
        "        combined = Concatenate()([spatial_features, temporal_features])\n",
        "        x = BatchNormalization()(combined)\n",
        "        x = Dense(256, activation=\"relu\")(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        x = Dense(128, activation=\"relu\")(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "        output = Dense(1, activation=\"sigmoid\", name=\"Output\")(x)\n",
        "\n",
        "        return Model(inputs=[frame_input, sequence_input], outputs=output)"
      ],
      "metadata": {
        "id": "g6kPFYQSWw_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Model Training**\n",
        "\n",
        "Train MADNet using:\n",
        "- Binary cross-entropy as the loss function.\n",
        "- Adam optimizer with a learning rate of 0.0001.\n",
        "- Early stopping and learning rate reduction on validation loss."
      ],
      "metadata": {
        "id": "88zOKh0IDXEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, learning_rate=0.0001):\n",
        "        self.model = model\n",
        "        self.model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "            loss=\"binary_crossentropy\",\n",
        "            metrics=[\"accuracy\", tf.keras.metrics.AUC()]\n",
        "        )\n",
        "\n",
        "    def train(self, train_dataset, valid_dataset, epochs=20, batch_size=16):\n",
        "        \"\"\"Train the model with provided datasets.\"\"\"\n",
        "        callbacks = [\n",
        "            EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
        "            ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=3, min_lr=1e-6)\n",
        "        ]\n",
        "\n",
        "        self.model.fit(\n",
        "            train_dataset,\n",
        "            validation_data=valid_dataset,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            callbacks=callbacks\n",
        "        )"
      ],
      "metadata": {
        "id": "gMZPpt4iDmkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **4. Evaluation and Saving the Model**\n",
        "\n",
        "Evaluate the model on a test dataset and save the trained weights."
      ],
      "metadata": {
        "id": "-5ZNBnAnDnfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def evaluate(self, test_dataset):\n",
        "        \"\"\"Evaluate the model on the test dataset.\"\"\"\n",
        "        results = self.model.evaluate(test_dataset)\n",
        "        print(f\"Test Loss: {results[0]:.4f}, Test Accuracy: {results[1]:.4f}, Test AUC: {results[2]:.4f}\")\n",
        "\n",
        "    def save_model(self, path):\n",
        "        \"\"\"Save the trained model.\"\"\"\n",
        "        self.model.save(path)\n",
        "        print(f\"Model saved to {path}\")\n"
      ],
      "metadata": {
        "id": "h3p9Uap3D2B2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}